# ğ“º Gebeya Lens ğ“º

## Decoding Ethiopiaâ€™s Telegram E-Commerce Chaos with AI/ML

This project extracts structured product data (Product, Price, Location) from Amharic Telegram channels and analyzes vendor performance for financial services.

## ğŸ”§ Tasks Overview
1. Scrape Telegram channels with Amharic vendor posts
2. Preprocess and normalize Amharic text
3. Label subset in CoNLL format
4. Fine-tune NER models (XLM-R, mBERT, etc.)
5. Compare and interpret models (SHAP, LIME)
6. Score vendors using extracted entities + metadata

## ğŸ“ Structure
```
ğŸ“¦ gebeyalens
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/
â”‚ â”œâ”€â”€ processed/
â”‚ â””â”€â”€ labeled/
â”œâ”€â”€ notebooks/
â”œâ”€â”€ scripts/
â”œâ”€â”€ models/
â”œâ”€â”€ reports/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ config.py
â””â”€â”€ README.md
```

## ğŸ‘¨â€ğŸ’» Tech Stack
- Python, Telethon
- HuggingFace Transformers
- Amharic NLP tools
- SHAP, LIME for interpretability

---
## ğŸ›  Task 1: Scraping Amharic E-Commerce Telegram Channels

### ğŸ¯ Objective  
Collect e-commerce posts from Amharic Telegram channels to build a raw dataset for entity recognition. Focused on extracting product details, pricing, locations, contacts, and delivery info.

### ğŸš€ Approach  

- **Tool**: `Telethon` for asynchronous interaction with the Telegram API.  
- **Channels Scraped**: 19 public e-commerce channels (e.g., `@ZemenExpress`, `@AwasMart`, `@belaclassic`, `@Leyueqa`)  
- **Excluded**: `@ethio_brand_collection` (private/inactive)

### ğŸ“Œ Data Fields  

| Field        | Description |
|--------------|-------------|
| `channel`    | Channel name (e.g., belaclassic) |
| `message_id` | Post ID (e.g., 1645) |
| `text`       | Post content (Amharic/English) |
| `timestamp`  | Date/time of post |
| `views`      | View count |
| `media_path` | Image file path (if available) |

### ğŸ“¤ Output  

- **File**: `data/raw/scraped.csv` (488 posts)  
- **Images**: Stored in `data/raw/photos/` (~60% posts include images)

### ğŸ“Š Results  

- **Total Posts**: 488  
- **Channels Covered**: 19  
- **No missing text**, **No duplicate rows**  
- **Top Channels**:  
  - `belaclassic` (50 posts)  
  - `qnashcom` (40 posts)  
  - `sinayelj` (11 posts)  

### ğŸ” Content Patterns  

- **Products**: Mixed-language descriptions (e.g., "PUMA SPIRIT", "á‹¨áŒ¨á‰…áˆ‹ áˆ…áƒáŠ“á‰µ áˆ›á‰€áŠá‹«")  
- **Prices**:  
  - â€œá‹‹áŒ‹á¦ 2,000 á‰¥áˆ­â€  
  - â€œPRICE 4900 á‰¥áˆ­â€  
- **Locations**:  
  - Amharic: â€œáˆ˜áŒˆáŠ“áŠ›â€  
  - English: â€œMexicoâ€  
- **Contacts**:  
  - Phone numbers: â€œ0944222069â€  
  - Telegram handles: â€œ@zemencallcenterâ€  
- **Delivery**: Terms like â€œáŠ¨áŠáƒ á‹²áˆŠá‰¨áˆªâ€, â€œá‰ áˆá‰°áˆ¨áŠá‰½â€

---

## âš ï¸ Challenges  

| Challenge               | Solution                                               |
|-------------------------|--------------------------------------------------------|
| Missing Channel         | Skipped `@ethio_brand_collection` (private/inactive)  |
| Non-Product Posts       | Detected and filtered greetings/promotions             |
| Language Mix            | Handled mixed Amharic-English formats                  |
| Telegram API Rate Limit | Managed using Telethon's built-in async mechanisms     |

---

## ğŸ“‚ Key Files  

- `scripts/telegram_scraper.py`: Core scraper logic  
- `run_scraper.py`: CLI runner with configs  
- `data/raw/scraped.csv`: Raw dataset  
- `data/raw/photos/`: Image attachments  

---

## ğŸ›  Task 2: Preprocess and Label Subset in CoNLL Format

### ğŸ¯ Objective  
Clean and normalize raw Telegram posts, then annotate a representative sample in CoNLL format for Named Entity Recognition (NER). Target entities include **Product**, **Price**, **Location**, **Contact**, and **Delivery**.

---

### ğŸš€ Approach  

#### ğŸ”„ Preprocessing

- Loaded `data/raw/scraped.csv` (488 rows from 19 channels) using `pandas`
- Filtered **non-product posts** (e.g., â€œEid Mubarakâ€, â€œá‰ áˆ¨áá‰µ á‰€áŠ•á‹â€) via keyword-based exclusion
- Normalized text by:
  - Removing ellipses (`...`)
  - Cleaning up Amharic-English mix
- Tokenized text using **space-based splitting**, effective for both scripts

#### ğŸ¯ Sampling

- Selected **~50 messages** using **stratified sampling** to ensure representation across channels
- Covered high-volume (e.g., `belaclassic`, `AwasMart`) and low-volume channels (e.g., `sinayelj`)

#### ğŸ·ï¸ Labeling

- Used `scripts/data_labeler.py`, a **semi-automated terminal labeling tool** for NER
- Tagged entities:
  - **Product**: e.g., â€œPUMA SPIRITâ€
  - **Price**: e.g., â€œ4900 á‰¥áˆ­â€
  - **Location**: e.g., â€œMexicoâ€
  - **Contact**: e.g., â€œ0944222069â€
  - **Delivery**: e.g., â€œáŠ¨áŠáƒ á‹²áˆŠá‰¨áˆªâ€
- Used **pattern-based suggestions** to speed up annotation  
  - Product: Tokens at start or before â€œá‹‹áŒ‹á¦â€/â€œPRICEâ€  
  - Price: Number after â€œá‹‹áŒ‹á¦â€ or â€œPRICEâ€, followed by â€œá‰¥áˆ­â€  
  - Contact: Phone patterns (â€œ09â€, â€œ+251â€), Telegram handles (â€œ@â€)  
  - Delivery: Terms like â€œá‰ áˆá‰°áˆ¨áŠá‰½â€, â€œáŠ¨áŠáƒâ€  
- Allowed **user override** of tags during labeling
- Output saved in `data/labeled/labeled.conll` with metadata (e.g., `message_id`, `channel`, `text`)

---

### ğŸ“Š Results  

- **Labeled Dataset**: ~50 messages, covering **all 19 channels**
- **Entity Distribution**:
  - `O`: 50% (non-entity tokens)
  - `Product`: 20%
  - `Price`: 15%
  - `Location`: 10%
  - `Contact/Delivery`: 5%
- **Handled Patterns**:
  - Price: â€œá‹‹áŒ‹á¦ 2,000 á‰¥áˆ­â€, â€œPRICE 4900 á‰¥áˆ­â€
  - Products: â€œDancing Cactus Toyâ€, â€œá‹¨áŒ¨á‰…áˆ‹ áˆ…áƒáŠ“á‰µ áˆ›á‰€áŠá‹«â€
  - Sparse terms like â€œáŠ¨áŠáƒ á‹²áˆŠá‰¨áˆªâ€ successfully captured
- **Quality**: No missing text; sampling ensured diverse and balanced training data

---

### âš ï¸ Challenges  

| Challenge            | Resolution                                                   |
|----------------------|--------------------------------------------------------------|
| Non-Product Posts    | Filtered using keywords like â€œáˆ±á‰ƒá‰½áŠ•â€, â€œEidâ€                   |
| Language Mix         | Tokenized and normalized Amharic-English blends              |
| Manual Labeling      | Semi-automated process with terminal input + suggestions     |
| Sparse Entities      | Expanded keyword lists for rare Delivery/Location terms      |

---

### ğŸ“‚ Key Files  

- `scripts/data_labeler.py`: Terminal-based labeling interface  
- `run_labeler.py`: Configurable runner for sampling + labeling  
- `data/labeled/labeled.conll`: Final labeled dataset in CoNLL format  
- `labeler.log`: Logs sampling stats and labeling progress  

---

# ğŸ›  Task 3: Fine-Tune NER Model

## ğŸ¯ Objective
Fine-tune a transformer-based Named Entity Recognition (NER) model to extract key entities (**Product**, **Price**, **Location**, **Contact**, **Delivery**) from Amharic Telegram messages, enabling structured data extraction for EthioMartâ€™s e-commerce platform.

---

## ğŸš€ Approach

### ğŸ§  Model Selection
- **Model**: `xlm-roberta-base`, chosen for its multilingual capabilities and strong performance on low-resource languages like Amharic.
- **Framework**: Hugging Face Transformers, using the `Trainer` API for efficient fine-tuning.

### ğŸ“Š Data Preparation
- **Input**: Labeled dataset from Task 2: `data/labeled/labeled.conll` (~50 messages with annotated entities).
- **Preprocessing**:
  - Loaded CoNLL data into dictionaries with `tokens`, `ner_tags`, `message_id`, `channel`, `text`.
  - Split into 80% training and 20% validation using `train_test_split`.
  - Tokenized with XLM-RoBERTa tokenizer, aligning subword tokens and labels (e.g., `B-Product`, `I-Price`, `O`).
  - Assigned `-100` to special tokens to ignore in loss computation.
  - Converted to Hugging Face `Dataset` format.

### âš™ï¸ Fine-Tuning
- **Environment**: Google Colab (T4 GPU).
- **Libraries**: `transformers`, `datasets`, `seqeval`, `torch`.
- **Hyperparameters**:
  - Batch size: `4` (CPU), `8` (GPU)
  - Epochs: `3`
  - Learning rate: `2e-5`
  - Warmup steps: `10`
  - Weight decay: `0.01`
  - Max sequence length: `128`
  - Gradient accumulation: `2` (effective batch size: 8)
  - Max steps: `30` (small dataset)
- **Training**:
  - Used `DataCollatorForTokenClassification` for padding.
  - Evaluated per epoch using `seqeval` metrics.
  - Saved best model to `models/ner_xlmr`.

---

## ğŸ“ Evaluation
- **Validation set**: ~10 samples
- **Metrics** (from `reports/ner_metrics.json`):
  - **F1-Score**: `0.629`
  - **Precision**: `0.855`
  - **Recall**: `0.497`

### ğŸ” Analysis
- High **precision** means predictions are accurate when made.
- Low **recall** suggests missed entitiesâ€”more data is needed.
- F1-score is a fair tradeoff for small data size.

- **Model Size**: ~1100 MB
- **Evaluation Time**: ~3.39s for ~10 samples (~0.34s/sample)

---

## âš ï¸ Challenges & Solutions

| Challenge                    | Resolution                                                             |
|-----------------------------|------------------------------------------------------------------------|
| Small Dataset (~50 msgs)    | Trained lightly (3 epochs, max 30 steps) to avoid overfitting          |
| Low Recall                  | Noted limitation; more labeled data could help                         |
| GPU Memory Constraints       | Reduced batch size, used gradient accumulation                         |
| Amharic Tokenization         | XLM-RoBERTa tokenizer handled it well; no major issues                 |

---

## ğŸ“‚ Key Files

- `scripts/fine_tune_ner.py`: Core fine-tuning logic (`NERFineTuner` class)
- `scripts/run_fine_tune.py`: CLI runner (configurable model name, epochs, batch size)
- `models/ner_xlmr/`: Fine-tuned model and tokenizer
- `reports/ner_metrics.json`: Evaluation metrics
- `fine_tune_ner.log`: Logs (training, evaluation)

